18单服务器高性能模式：PPC与TPC

高性能架构设计主要集中在两方面：
    1尽量提升单服务器的性能，将单服务器的性能发挥到极致
    2如果单服务器无法支撑性能，设计服务器集群方案

架构设计决定了系统性能的上线，实现细节决定了系统性能的下限

单服务器高性能的关键之一就是服务器采取的并发模型，并发模型两个关键设计点：
    --服务器如何管理连接
    --服务器如何处理请求
以上两个设计点最终都和操作系统的I/O模型及进程模型相关。
I/O模型:阻塞、非阻塞、同步、异步
进程模型：单进程、多进程、多线程

=================单服务器高性能模式：PPC与TPC=============================

PPC
    Process Per Connection 每次有新的连接就新建一个进程去专门处理这个连接的请求。
    问题：fork代价高
          父子进程通信复杂
          支持的并发连接数量有限
    prefork 提前创建进程 pre-fork，系统启动的时候就预先创建好进程，然后才开始接受用户的请求，当有新的连接进来的时候，就可以省去fork进程的操作，让用户访问更快，体验更好。
          实现关键：多个子进程都accept同一个socket，当有新的连接进入时，操作系统保证只有一个进程能最后accept成功。
                    惊群现象——linux2.6版本后内核已经解决了accept惊群问题。
TPC
    Thread Per Connection 每次有新的连接就创建一个线程去专门处理这个连接的请求。
        线程更轻量级、资源消耗少；多线程共享内存空间，线程通信比进程通信更简单。
        TCP解决或弱化了PPC fork代价高、父子进程通信复杂的问题。
    问题：
        创建线程也有代价，高并发-每秒上万连接还是有性能问题
        无须进程通信，线程间互斥和共享又引入了复杂度，可能死锁
        多线程会出现相互影响的情况，某个线程异常，可能导致整个进程退出——如内存越界
    prethread

    PPC与TPC模式，支持的并发连接都不高，最大也就几百。

其他知识：
===========PPC与TPC适用的系统==================
1 不同并发模式的选择，还要考虑三个指标，分别是响应时间RT、并发数Concurrency、吞吐量TPS。三者关系，吞吐量=并发数/平均响应时间。
    三高系统：秒杀、即时通讯，不能使用
    三低系统：ToB系统，运营类、管理类系统，一般可以使用
    高吞吐系统，如果是内存计算为主，一般可以使用，如果是网络IO为主，一般不能使用。
2 PPC与TPC支持的最大连接数差不多，都是几百个，适用的场景也是差不多的。
  这两种方式都不支持高连接数的场景，所以适用场景如下：
    --常量连接海量请求。比如数据库、redis、kafka等等
    --常量连接常量请求。比如企业内部网址 


